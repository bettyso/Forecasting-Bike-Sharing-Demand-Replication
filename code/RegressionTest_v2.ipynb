{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import 2013 Bike Sharing data\n",
      "2017-11-26 04:55:19 - Start processing LinearRegression\n",
      "2017-11-26 04:55:28 - Start processing RidgeRegression for solver: auto\n",
      "2017-11-26 04:55:36 - Start processing RidgeRegression for solver: svd\n",
      "2017-11-26 04:55:45 - Start processing RidgeRegression for solver: lsqr\n",
      "2017-11-26 04:55:54 - Start processing RidgeRegression for solver: sparse_cg\n",
      "2017-11-26 04:56:02 - Start processing RidgeRegression for solver: saga\n",
      "2017-11-26 04:56:40 - Start processing BayesianRidge\n",
      "2017-11-26 04:57:00 - Start processing SGDRegressor\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import xgboost as xgb\n",
    "    \n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from math import *\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "ifile = \"D:/Capston/2013_Hour_By_Tract.csv\"\n",
    "scores_cols = ['Test', 'Test_score']\n",
    "statfile = \"D:/Capston/RegTest_\" + dt.datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".txt\"\n",
    "\n",
    "features=['tractID','mday','hr','temp',\n",
    "          'season', 'weather', 'weekday', 'mth',\n",
    "          #'tempCluster','hrCluster',\n",
    "          'holiday','workingday', 'windspeed','humidity']\n",
    "features2=['tractID','mday','hr',\n",
    "          'season_0','season_1','season_2','season_3',\n",
    "          'weather_0','weather_1','weather_2','weather_3',\n",
    "          'weekday_0','weekday_1','weekday_2','weekday_3','weekday_4','weekday_5','weekday_6',\n",
    "          'mth_0','mth_1','mth_2','mth_3','mth_4','mth_5','mth_6','mth_7','mth_8','mth_9','mth_10','mth_11',\n",
    "          'tempCluster','hrCluster',\n",
    "          'holiday','workingday', 'windspeed','humidity']\n",
    "n_job=4\n",
    "#score='neg_mean_squared_error'\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def read_data():\n",
    "    ds = pd.read_csv(ifile, sep=',', header=0)\n",
    "    ds['dteday'] = pd.to_datetime(ds['dteday'], format='%Y-%m-%d')\n",
    "    ds['mday'] = ds['dteday'].dt.day \n",
    "    \n",
    "    ds['casual'] = [log1p(x) for x in ds['casual']]\n",
    "    ds['registered'] = [log1p(x) for x in ds['registered']]\n",
    "    ds['cnt'] = [log1p(x) for x in ds['cnt']]\n",
    "    \n",
    "    return remove_columns(ds, ['dteday', 'yr'])\n",
    "\n",
    "\n",
    "def remove_columns(ds, drop_cols):\n",
    "    ds = ds.drop(drop_cols, axis = 1)\n",
    "\n",
    "    return ds\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def temp_cluster(temp):\n",
    "\n",
    "    if temp <= 1.0: \n",
    "        return 0\n",
    "    elif temp > 1.0 and temp <= 15.0:\n",
    "        return 1\n",
    "    elif temp > 15.0 and temp <= 22.0:\n",
    "        return 2\n",
    "    elif temp > 22.0 and temp <= 31.0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "\n",
    "def hr_cluster(hr):\n",
    "\n",
    "    if hr <= 6.5: \n",
    "        return 0\n",
    "    elif hr > 6.5 and hr <= 7.5:\n",
    "        return 1\n",
    "    elif hr > .5 and hr <= 8.5:\n",
    "        return 2\n",
    "    elif hr > 8.5 and hr <= 16:\n",
    "        return 3\n",
    "    elif hr > 16 and hr <= 18:\n",
    "        return 4\n",
    "    elif hr > 18 and hr <= 20:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "     \n",
    "\n",
    "def transform1_data(ds):\n",
    "\n",
    "    enc = OneHotEncoder(sparse=False)  \n",
    "    n = ds['season'].shape[0]\n",
    "    enc_array = pd.DataFrame(sparse.csr_matrix(enc.fit_transform(ds['season'].values.reshape(-1, 1))).todense().reshape(n, 1, 4))\n",
    "    ds['season_0'] = enc_array[[0]]\n",
    "    ds['season_1'] = enc_array[[1]] \n",
    "    ds['season_2'] = enc_array[[2]] \n",
    "    ds['season_3'] = enc_array[[3]]     \n",
    "\n",
    "    enc_array = pd.DataFrame(sparse.csr_matrix(enc.fit_transform(ds['weather'].values.reshape(-1, 1))).todense().reshape(n, 1, 4))\n",
    "    ds['weather_0'] = enc_array[[0]]\n",
    "    ds['weather_1'] = enc_array[[1]] \n",
    "    ds['weather_2'] = enc_array[[2]] \n",
    "    ds['weather_3'] = enc_array[[3]]     \n",
    "\n",
    "    enc_array = pd.DataFrame(sparse.csr_matrix(enc.fit_transform(ds['weekday'].values.reshape(-1, 1))).todense().reshape(n, 1, 7))\n",
    "    ds['weekday_0'] = enc_array[[0]]\n",
    "    ds['weekday_1'] = enc_array[[1]] \n",
    "    ds['weekday_2'] = enc_array[[2]] \n",
    "    ds['weekday_3'] = enc_array[[3]]     \n",
    "    ds['weekday_4'] = enc_array[[4]]\n",
    "    ds['weekday_5'] = enc_array[[5]] \n",
    "    ds['weekday_6'] = enc_array[[6]] \n",
    "    \n",
    "    enc_array = pd.DataFrame(sparse.csr_matrix(enc.fit_transform(ds['mth'].values.reshape(-1, 1))).todense().reshape(n, 1, 12))\n",
    "    ds['mth_0'] = enc_array[[0]]\n",
    "    ds['mth_1'] = enc_array[[1]] \n",
    "    ds['mth_2'] = enc_array[[2]] \n",
    "    ds['mth_3'] = enc_array[[3]]     \n",
    "    ds['mth_4'] = enc_array[[4]]\n",
    "    ds['mth_5'] = enc_array[[5]] \n",
    "    ds['mth_6'] = enc_array[[6]] \n",
    "    ds['mth_7'] = enc_array[[7]]\n",
    "    ds['mth_8'] = enc_array[[8]] \n",
    "    ds['mth_9'] = enc_array[[9]] \n",
    "    ds['mth_10'] = enc_array[[10]]     \n",
    "    ds['mth_11'] = enc_array[[11]]\n",
    "\n",
    "    ds = transform2_data(ds)\n",
    "    \n",
    "    return remove_columns(ds, ['season', 'weather', 'weekday', 'mth', 'temp'])\n",
    "\n",
    "        \n",
    "def transform2_data(df):\n",
    "        \n",
    "    df['hrCluster'] = df.apply(lambda x: hr_cluster(x['hr']), axis = 1) \n",
    "    df['tempCluster'] = df.apply(lambda x: temp_cluster(x['temp']), axis = 1) \n",
    "        \n",
    "    df['tractID'] = MinMaxScaler().fit_transform(df['tractID'].astype(float).values.reshape(-1, 1))\n",
    "    df['mday'] = StandardScaler().fit_transform(df['mday'].astype(float).values.reshape(-1, 1))\n",
    "    df['hr'] = StandardScaler().fit_transform(df['hr'].astype(float).values.reshape(-1, 1))\n",
    "    df['weekday'] = StandardScaler().fit_transform(df['weekday'].astype(float).values.reshape(-1, 1))\n",
    "    df['weather'] = StandardScaler().fit_transform(df['weather'].astype(float).values.reshape(-1, 1))\n",
    "    df['temp'] = StandardScaler().fit_transform(df['temp'].values.reshape(-1, 1))\n",
    "    df['mth'] = StandardScaler().fit_transform(df['mth'].astype(float).values.reshape(-1, 1))\n",
    "    df['season'] = StandardScaler().fit_transform(df['season'].astype(float).values.reshape(-1, 1))    \n",
    "    df['windspeed'] = [log1p(x) for x in df['windspeed']]\n",
    "    df['humidity'] = [log1p(x) for x in df['humidity']]\n",
    "    \n",
    "    #print(df.head())\n",
    "    return df\n",
    "\n",
    "\n",
    "def rmsle(predicted, actual, TestScores, testname):\n",
    "    df = pd.concat([actual, predicted], axis = 1)\n",
    "    df['err'] = df.apply(lambda x: pow((log1p(x['cnt']) - log1p(x['pred'])), 2), axis = 1)\n",
    "    \n",
    "    #mean_squared_log_error(actual, predicted)\n",
    "    tmp = pd.DataFrame([[testname, sqrt(df['err'].sum() / len(df))]],\n",
    "                       columns = scores_cols)\n",
    "\n",
    "    tmp.to_csv(statfile, mode='a', header = False, index = False, sep = '|')\n",
    "    TestScores = TestScores.append(tmp, ignore_index = True)\n",
    "\n",
    "    return TestScores\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def linearregression(X_data, y_data, TestScores):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "          \" - Start processing LinearRegression\")\n",
    "\n",
    "    model = LinearRegression(normalize = False)\n",
    "    X_data['pred'] = cross_val_predict(model, X_data, y_data, cv=10)\n",
    "\n",
    "    TestScores = rmsle(X_data['pred'], y_data, TestScores, 'LinearRegression')\n",
    "\n",
    "    return TestScores\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def ridgeregression(X_data, y_data, TestScores):\n",
    "    from sklearn.linear_model import Ridge\n",
    "    \n",
    "    for sv in ['auto', 'svd', 'lsqr', 'sparse_cg', 'saga']:\n",
    "        print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "              \" - Start processing RidgeRegression for solver: %s\" %(sv))\n",
    "\n",
    "        model = Ridge(solver=sv, normalize = False, random_state=212)\n",
    "        X_data['pred'] = cross_val_predict(model, X_data, y_data, cv=10)\n",
    "\n",
    "        TestScores = rmsle(X_data['pred'], y_data, TestScores, 'RidgeRegression-' + sv)\n",
    "\n",
    "    return TestScores\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def bayesianridge(X_data, y_data, TestScores):\n",
    "    from sklearn.linear_model import BayesianRidge\n",
    "        \n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "            \" - Start processing BayesianRidge\")\n",
    "    model = BayesianRidge(n_iter=1000, normalize = False)\n",
    "    X_data['pred'] = cross_val_predict(model, X_data, y_data.values.ravel(), cv=10)\n",
    "\n",
    "    TestScores = rmsle(X_data['pred'], y_data, TestScores, 'BayesianRidge')\n",
    "\n",
    "    return TestScores\n",
    "          \n",
    "# =====================================================================\n",
    "\n",
    "def sgdregressor(X_data, y_data, TestScores):\n",
    "    from sklearn.linear_model import SGDRegressor\n",
    "    \n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "            \" - Start processing SGDRegressor\")\n",
    "    model = SGDRegressor(max_iter=1000, random_state=212)\n",
    "    X_data['pred'] = cross_val_predict(model, X_data, y_data.values.ravel(), cv=10)\n",
    "\n",
    "    TestScores = rmsle(X_data['pred'], y_data, TestScores, 'SGDRegressor')\n",
    "\n",
    "    return TestScores          \n",
    "          \n",
    "# =====================================================================\n",
    "\n",
    "def gradientboostingregression(X_data, y_data, TestScores):\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#    for ne in [50, 100, 150, 200, 250, 300, 350, 400]:\n",
    "    for ne in [250, 300, 300, 350, 400]:\n",
    "        for md in [30, 35, 40, 45, 50]:\n",
    "            print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                    \" - Start processing GradientBoostingRegressor for n_estimator:%s  max_depth:%s\" %(ne, md))\n",
    "            model = GradientBoostingRegressor(n_estimators = ne, max_depth = md,\n",
    "                                            learning_rate = 0.1)\n",
    "            X_data['pred'] = cross_val_predict(model, X_data, y_data.values.ravel(), cv=10)\n",
    "\n",
    "            TestScores = rmsle(X_data['pred'], y_data, TestScores, \"GradientBoostingRegressor %s-%s\" %(ne, md))  \n",
    "\n",
    "    return TestScores\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def randomforestregression(X_data, y_data, TestScores):\n",
    "\n",
    "    for ne in [300, 350, 400,450, 500, 550, 600]:\n",
    "        for md in [30, 35, 40, 45, 50]:\n",
    "            print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                    \" - Start processing RandomForestRegressor for n_estimator:%s  max_depth:%s\" %(ne, md))\n",
    "            model = RandomForestRegressor(n_estimators = ne, max_depth = md, \n",
    "                                        max_features = 'auto', random_state = 120)\n",
    "            X_data['pred'] = cross_val_predict(model, X_data, y_data.values.ravel(), cv=10)\n",
    "\n",
    "            TestScores = rmsle(X_data['pred'], y_data, TestScores, \"RandomForestRegressor %s-%s\" %(ne, md))                                    \n",
    "\n",
    "    return TestScores\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def extratreesregression(X_data, y_data, TestScores):\n",
    "\n",
    "    for ne in [100, 150, 200, 250, 300, 350, 400]:\n",
    "        for md in [20, 25, 30, 35, 40, 45, 50]:\n",
    "            print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                  \" - Start processing ExtraTreesRegressor for n_estimator:%s  max_depth:%s\" %(ne, md))\n",
    "            model = ExtraTreesRegressor(n_estimators = ne, max_depth = md, \n",
    "                                        max_features = 'auto', random_state = 120)\n",
    "            X_data['pred'] = cross_val_predict(model, X_data, y_data.values.ravel(), cv=10)\n",
    "\n",
    "            TestScores = rmsle(X_data['pred'], y_data, TestScores, \"ExtraTreesRegressor %s-%s\" %(ne, md))                                       \n",
    "\n",
    "    return TestScores\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def baggingregression(X_data, y_data, TestScores):\n",
    "    from sklearn.ensemble import BaggingRegressor\n",
    "    \n",
    "    for ne in [100, 150, 200, 250, 300, 350, 400]:\n",
    "        print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                      \" - Start processing BaggingRegressor for n_estimator:%s\" %(ne))\n",
    "        model = BaggingRegressor(n_estimators = ne, bootstrap = True,\n",
    "                               bootstrap_features = True, random_state = 120)\n",
    "        X_data['pred'] = cross_val_predict(model, X_data, y_data.values.ravel(), cv=10)\n",
    "\n",
    "        TestScores = rmsle(X_data['pred'], y_data, TestScores, \"BaggingRegressor %s\" %(ne))\n",
    "\n",
    "    return TestScores\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def xgboost(X_data, y_data, TestScores):\n",
    "    \n",
    "    for ne in [200, 250, 300, 350, 400]:\n",
    "        for lr in [0.05, 0.1]:\n",
    "            for bt in ['gblinear', 'dart']:\n",
    "                print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                        \" - Start processing XGBRegressor for n_estimator: %s learning-rate: %s booster: %s\" %(ne, lr, bt))\n",
    "                model = xgb.XGBRegressor(n_estimators = ne, learning_rate=lr,\n",
    "                                         booster=bt, random_state = 120)\n",
    "                X_data['pred'] = cross_val_predict(model, X_data, y_data.values.ravel(), cv=10)\n",
    "\n",
    "                TestScores = rmsle(X_data['pred'], y_data, TestScores, \"XGBRegressor %s-%s-%s\" %(ne, lr, bt))\n",
    "\n",
    "    return TestScores\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def stacking(X_data, y_data):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_log_error    \n",
    "    from vecstack import stacking\n",
    "\n",
    "    tmp = bike.loc[bike['mday'] <= 20]\n",
    "    X_train = tmp[features2].values\n",
    "    y_train = tmp['cnt'].values.ravel()\n",
    "\n",
    "    tmp = bike.loc[bike['mday'] > 20]\n",
    "    X_test = tmp[features2].values\n",
    "    y_test = tmp.loc[:,'cnt']\n",
    "\n",
    "    mXgb = xgb.XGBRegressor(n_estimators = 50, learning_rate=0.05,booster='dart', seed = 0)\n",
    "    mEtr = ExtraTreesRegressor(n_estimators = 200, max_depth = 35,max_features = 'auto', random_state = 0)\n",
    "    mReg = RandomForestRegressor(n_estimators = 200, max_depth = 35,max_features = 'auto', random_state = 120)\n",
    "    models = [mXgb, mReg, mEtr]\n",
    "\n",
    "    S_train, S_test = stacking(models, X_train, y_train, X_test, regression = True,\n",
    "                               metric=mean_squared_log_error, n_folds = 10)\n",
    "    model = xgb.XGBRegressor(seed = 0, j_jobs = 2, learning_rate = 0.1, n_estimators = 200, max_depth = 35)\n",
    "\n",
    "    model = model.fit(S_train, y_train)\n",
    "    y_test['pred'] = model.predict(S_test)\n",
    "    TestScores = rmsle( y_test['pred'],  y_test, TestScores, \"Stacking\")\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "print(\"Import 2013 Bike Sharing data\")\n",
    "TestScores = pd.DataFrame(columns = scores_cols)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Linear Regression perform much better without one-hot encode data\n",
    "    bike = read_data()\n",
    "    bike = transform2_data(bike)\n",
    "    y = bike[['cnt']]\n",
    "    X = bike.loc[:,features]\n",
    "    linearregression(X, y, TestScores)  # LinearRegression|0.2961375389416182\n",
    "\n",
    "    ridgeregression(X, y, TestScores)\n",
    "    # RidgeRegression-auto|0.29631404684815926\n",
    "    # RidgeRegression-svd|0.29932419093854423\n",
    "\n",
    "    bayesianridge(X, y, TestScores)  # BayesianRidge|0.2976985295048054\n",
    "\n",
    "    bike = read_data()\n",
    "    bike = transform1_data(bike)\n",
    "    y = bike[['cnt']]\n",
    "    X = bike.loc[:,features2]\n",
    "    \n",
    "    sgdregressor(X, y, TestScores)\n",
    "        \n",
    "    stacking(X, y)\n",
    "\n",
    "    randomforestregression(X, y, TestScores)\n",
    "\n",
    "    extratreesregression(X, y, TestScores)\n",
    "\n",
    "    baggingregression(X, y, TestScores)\n",
    "\n",
    "    xgboost(X, y, TestScores)\n",
    "\n",
    "    gradientboostingregression(X, y, TestScores)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
