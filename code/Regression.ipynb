{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import 2013 Bike Sharing data\n",
      "   tractID  jday  season  mth  hr  holiday  weekday  workingday  weather  \\\n",
      "0        2     1       1    1   0        1        2           0        2   \n",
      "1        8     1       1    1   0        1        2           0        2   \n",
      "2       16     1       1    1   0        1        2           0        2   \n",
      "3       17     1       1    1   0        1        2           0        2   \n",
      "4       19     1       1    1   0        1        2           0        2   \n",
      "\n",
      "   temp  atemp  humidity  windspeed  casual  registered  cnt  mday  \n",
      "0   3.3    0.4        68       11.1       0           1    1     1  \n",
      "1   3.3    0.4        68       11.1       0           1    1     1  \n",
      "2   3.3    0.4        68       11.1       0           1    1     1  \n",
      "3   3.3    0.4        68       11.1       0           1    1     1  \n",
      "4   3.3    0.4        68       11.1       0           2    2     1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse \n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_log_error    \n",
    "from vecstack import stacking\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from math import *\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "ifile = \"D:/Capston/2013_Hour_By_Tract.csv\"\n",
    "scores_cols = ['Test', 'Test_score']\n",
    "statfile = \"D:/Capston/RegressionTest_\" + dt.datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".txt\"\n",
    "n_job=2\n",
    "features=['tractID','mday','hr','tempCluster','hrCluster',\n",
    "          'season_0','season_1','season_2','season_3',\n",
    "          'weather_0','weather_1','weather_2','weather_3',\n",
    "          'weekday_0','weekday_1','weekday_2','weekday_3','weekday_4','weekday_5','weekday_6',\n",
    "          'mth_0','mth_1','mth_2','mth_3','mth_4','mth_5','mth_6','mth_7','mth_8','mth_9','mth_10','mth_11',\n",
    "          'holiday','workingday', 'windspeed','humidity']\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def read_data():\n",
    "    ds = pd.read_csv(ifile, sep=',', header=0)\n",
    "    ds['dteday'] = pd.to_datetime(ds['dteday'], format='%Y-%m-%d')\n",
    "    ds['mday'] = ds['dteday'].dt.day \n",
    "    \n",
    "    return remove_columns(ds, ['dteday', 'yr'])\n",
    "\n",
    "\n",
    "def remove_columns(ds, drop_cols):\n",
    "    ds = ds.drop(drop_cols, axis = 1)\n",
    "\n",
    "    return ds\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def store_scores(scores, TestScores, testname):\n",
    "    df = pd.DataFrame([[testname,\n",
    "                        scores['fit_time'].mean(),\n",
    "                        scores['score_time'].mean(),\n",
    "                        (-1 * scores['test_score'].mean()),\n",
    "                        (-1 * scores['train_score'].mean())]],\n",
    "                      columns = scores_cols)\n",
    "\n",
    "    df.to_csv(statfile, mode='a', header = False, index = False, sep = '|')\n",
    "    TestScores = TestScores.append(df, ignore_index = True)\n",
    "    #print (TestScores)\n",
    "    return TestScores\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def split_list(alist, wanted_parts = 1):\n",
    "    length = len(alist)\n",
    "    return [ alist[i * length // wanted_parts: (i + 1) * length // wanted_parts]\n",
    "            for i in range(wanted_parts) ]\n",
    "\n",
    "\n",
    "def data_cluster(df, grpBy, cluster_num):\n",
    "    \n",
    "    cluster_data = df.groupby([grpBy]).agg(lambda x: x.mean())[['cnt']]\n",
    "    model = cluster.KMeans(n_clusters = cluster_num)\n",
    "    \n",
    "    return np.array(model.fit_predict(split_list(cluster_data.iloc[:,0].values, len(cluster_data))))\n",
    "\n",
    "\n",
    "def temp_cluster(temp):\n",
    "\n",
    "    if temp <= 1.0: \n",
    "        return 0\n",
    "    elif temp > 1.0 and temp <= 15.0:\n",
    "        return 1\n",
    "    elif temp > 15.0 and temp <= 22.0:\n",
    "        return 2\n",
    "    elif temp > 22.0 and temp <= 31.0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "\n",
    "def hr_cluster(hr):\n",
    "\n",
    "    if hr <= 6.5: \n",
    "        return 0\n",
    "    elif hr > 6.5 and hr <= 7.5:\n",
    "        return 1\n",
    "    elif hr > .5 and hr <= 8.5:\n",
    "        return 2\n",
    "    elif hr > 8.5 and hr <= 16:\n",
    "        return 3\n",
    "    elif hr > 16 and hr <= 18:\n",
    "        return 4\n",
    "    elif hr > 18 and hr <= 20:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "     \n",
    "\n",
    "def transform1_data(ds):\n",
    "    \n",
    "    ds['hrCluster'] = ds.apply(lambda x: hr_cluster(x['hr']), axis = 1) \n",
    "    ds['tempCluster'] = ds.apply(lambda x: temp_cluster(x['temp']), axis = 1) \n",
    "\n",
    "    enc = OneHotEncoder(sparse=False)  \n",
    "    n = ds['season'].shape[0]\n",
    "    enc_array = pd.DataFrame(sparse.csr_matrix(enc.fit_transform(ds['season'].values.reshape(-1, 1))).todense().reshape(n, 1, 4))\n",
    "    ds['season_0'] = enc_array[[0]]\n",
    "    ds['season_1'] = enc_array[[1]] \n",
    "    ds['season_2'] = enc_array[[2]] \n",
    "    ds['season_3'] = enc_array[[3]]     \n",
    "\n",
    "    enc_array = pd.DataFrame(sparse.csr_matrix(enc.fit_transform(ds['weather'].values.reshape(-1, 1))).todense().reshape(n, 1, 4))\n",
    "    ds['weather_0'] = enc_array[[0]]\n",
    "    ds['weather_1'] = enc_array[[1]] \n",
    "    ds['weather_2'] = enc_array[[2]] \n",
    "    ds['weather_3'] = enc_array[[3]]     \n",
    "\n",
    "    enc_array = pd.DataFrame(sparse.csr_matrix(enc.fit_transform(ds['weekday'].values.reshape(-1, 1))).todense().reshape(n, 1, 7))\n",
    "    ds['weekday_0'] = enc_array[[0]]\n",
    "    ds['weekday_1'] = enc_array[[1]] \n",
    "    ds['weekday_2'] = enc_array[[2]] \n",
    "    ds['weekday_3'] = enc_array[[3]]     \n",
    "    ds['weekday_4'] = enc_array[[4]]\n",
    "    ds['weekday_5'] = enc_array[[5]] \n",
    "    ds['weekday_6'] = enc_array[[6]] \n",
    "    \n",
    "    enc_array = pd.DataFrame(sparse.csr_matrix(enc.fit_transform(ds['mth'].values.reshape(-1, 1))).todense().reshape(n, 1, 12))\n",
    "    ds['mth_0'] = enc_array[[0]]\n",
    "    ds['mth_1'] = enc_array[[1]] \n",
    "    ds['mth_2'] = enc_array[[2]] \n",
    "    ds['mth_3'] = enc_array[[3]]     \n",
    "    ds['mth_4'] = enc_array[[4]]\n",
    "    ds['mth_5'] = enc_array[[5]] \n",
    "    ds['mth_6'] = enc_array[[6]] \n",
    "    ds['mth_7'] = enc_array[[0]]\n",
    "    ds['mth_8'] = enc_array[[1]] \n",
    "    ds['mth_9'] = enc_array[[2]] \n",
    "    ds['mth_10'] = enc_array[[3]]     \n",
    "    ds['mth_11'] = enc_array[[4]]\n",
    "\n",
    "    return remove_columns(ds, ['season', 'weather', 'weekday', 'mth', 'temp'])\n",
    "\n",
    "        \n",
    "def transform2_data(df):\n",
    "        \n",
    "    df['casual'] = [log1p(x) for x in df['casual']]\n",
    "    df['registered'] = [log1p(x) for x in df['registered']]\n",
    "    df['cnt'] = [log1p(x) for x in df['cnt']]\n",
    "\n",
    "    df['tractID'] = MinMaxScaler().fit_transform(df['tractID'].astype(float).values.reshape(-1, 1))\n",
    "    df['hr'] = StandardScaler().fit_transform(df['hr'].astype(float).values.reshape(-1, 1))\n",
    "    df['mday'] = StandardScaler().fit_transform(df['mday'].astype(float).values.reshape(-1, 1))\n",
    "    df['windspeed'] = [log1p(x) for x in df['windspeed']]\n",
    "    df['humidity'] = [log1p(x) for x in df['humidity']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def rmsle(predicted, actual, TestScores, testname):\n",
    "    df = pd.concat([actual, predicted], axis = 1)\n",
    "    df['err'] = df.apply(lambda x: pow(log1p(x['cnt']) - log1p(fabs(x['pred'])), 2), axis = 1)\n",
    "    error = df['err'].sum()\n",
    "\n",
    "    tmp = pd.DataFrame([[testname, sqrt(df['err'].sum() / len(df))]],\n",
    "                       columns = scores_cols)\n",
    "\n",
    "    tmp.to_csv(statfile, mode='a', header = False, index = False, sep = '|')\n",
    "    TestScores = TestScores.append(tmp, ignore_index = True)\n",
    "\n",
    "    return TestScores\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "def runRegression(model, testname, Testscores):\n",
    "\n",
    "    tmp = bike.loc[bike['mday'] <= 20]\n",
    "    X_train = tmp[features]\n",
    "    if testname == 'LinearRegression' or testname == 'RidgeRegression':\n",
    "        y_train = tmp['cnt']\n",
    "    else:\n",
    "        y_train = tmp['cnt'].values.ravel()\n",
    "\n",
    "    tmp = bike.loc[bike['mday'] > 20]\n",
    "    X_test = tmp.loc[:,features]\n",
    "    y_test = tmp.loc[:,['cnt']]\n",
    "\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    X_test['pred'] = pd.DataFrame(model.predict(X_test))\n",
    "\n",
    "    Testscores=rmsle( X_test['pred'], y_test, Testscores, testname)\n",
    "\n",
    "    return Testscores\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "print(\"Import 2013 Bike Sharing data\")\n",
    "bike = read_data()\n",
    "TestScores = pd.DataFrame(columns = scores_cols)\n",
    "\n",
    "print(bike.head())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    bike = transform1_data(bike)\n",
    "    \n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "          \" - Start processing LinearRegression\")\n",
    "    model = LinearRegression(normalize = True)\n",
    "    TestScores = runRegression(model,'LinearRegression', TestScores) \n",
    "\n",
    "    for sv in ['auto', 'svd', 'lsqr', 'sparse_cg', 'saga']:\n",
    "        print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "              \" - Start processing RidgeRegression for solver: %s\" %(sv))\n",
    "        model = Ridge(solver=sv, normalize = True, random_state=212)\n",
    "        TestScores = runRegression(model,'RidgeRegression', TestScores)\n",
    "    \n",
    "\n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "            \" - Start processing BayesianRidge\")\n",
    "    model = BayesianRidge(n_iter=1000, normalize = True)\n",
    "    TestScores = runRegression(model, 'BayesianRidge', TestScores)\n",
    "    \n",
    "\n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "            \" - Start processing SGDRegressor\")\n",
    "    model = SGDRegressor(n_iter=1000, random_state=212)\n",
    "    TestScores = runRegression(model, 'SGDRegressor', TestScores)\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                    \" - Start processing RandomForestRegressor\")\n",
    "    model = RandomForestRegressor(n_estimators = 300, max_depth = 35, \n",
    "                                  max_features = 'auto', random_state = 120)\n",
    "    TestScores = runRegression(model, 'RandomForestRegressor', TestScores)\n",
    "    \n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                      \" - Start processing ExtraTreesRegressor\")\n",
    "    model = ExtraTreesRegressor(n_estimators = 300, max_depth =35, \n",
    "                                            max_features = 'auto', random_state = 120)\n",
    "    TestScores = runRegression(model, 'ExtraTreesRegressor', TestScores)\n",
    "\n",
    "\n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                      \" - Start processing BaggingRegressor\")\n",
    "    model = BaggingRegressor(n_estimators = 200, bootstrap = True,\n",
    "                               bootstrap_features = True, random_state = 120)\n",
    "    TestScores = runRegression(model, 'BaggingRegressor', TestScores)\n",
    "    \n",
    "\n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                        \" - Start processing XGBRegressor\")\n",
    "    model = xgb.XGBRegressor(n_estimators = 250, learning_rate=0.1,\n",
    "                                         booster='gblinear', random_state = 120)\n",
    "    TestScores = runRegression(model, 'XGBRegressor', TestScores)\n",
    "    \n",
    "# =====================================================================\n",
    "\n",
    "    tmp = bike.loc[bike['mday'] <= 20]\n",
    "    X_train = tmp[features].values\n",
    "    y_train = tmp['cnt'].values.ravel()\n",
    "\n",
    "    tmp = bike.loc[bike['mday'] > 20]\n",
    "    X_test = tmp[features].values\n",
    "    y_test = tmp['cnt'].values.ravel()\n",
    "    mXgb = xgb.XGBRegressor(n_estimators = 50, learning_rate=0.05,booster='dart', seed = 0)\n",
    "    mEtr = ExtraTreesRegressor(n_estimators = 200, max_depth = 35,max_features = 'auto', random_state = 0)\n",
    "    mReg = RandomForestRegressor(n_estimators = 200, max_depth = 35,max_features = 'auto', random_state = 120)\n",
    "    models = [mXgb, mReg, mEtr]\n",
    "\n",
    "    S_train, S_test = stacking(models, X_train, y_train, X_test, regression = True,\n",
    "                               metric=mean_squared_log_error, n_folds = 5)\n",
    "    model = xgb.XGBRegressor(seed = 0, j_jobs = 2, learning_rate = 0.1, n_estimators = 200, max_depth = 35)\n",
    "    model = model.fit(S_train, y_train)\n",
    "    y_pred = model.predict(S_test)\n",
    "    \n",
    "    print ('Final prediction score: [%.8f]' % mean_squared_log_error(y_test, y_pred))\n",
    "    tmp = pd.DataFrame([['Stacking', mean_squared_log_error(y_test, y_pred)]],\n",
    "                       columns = scores_cols)\n",
    "\n",
    "    tmp.to_csv(statfile, mode='a', header = False, index = False, sep = '|')\n",
    "    TestScores = TestScores.append(tmp, ignore_index = True)\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "                    \" - Start processing GradientBoostingRegressor\")\n",
    "    model = GradientBoostingRegressor(n_estimators = 200, max_depth = 30,\n",
    "                                           learning_rate = 0.1)\n",
    "    TestScores = runRegression(model, 'GradientBoostingRegressor', TestScores)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
